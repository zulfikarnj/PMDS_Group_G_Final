{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "import yaml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(params):\n",
    "    x_train = joblib.load(params['X_PATH_TRAIN'])\n",
    "    y_train = joblib.load(params['Y_PATH_TRAIN'])\n",
    "    x_valid = joblib.load(params['X_PATH_VALID'])\n",
    "    y_valid = joblib.load(params['Y_PATH_VALID'])\n",
    "    x_test = joblib.load(params['X_PATH_TEST'])\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid, x_test\n",
    "\n",
    "def model_lasso():\n",
    "    param_dist = {'alpha': np.random.uniform(0.01,1,3)}\n",
    "    base_model = Lasso(random_state=42, selection='random')\n",
    "    return param_dist, base_model\n",
    "\n",
    "\n",
    "def model_rf():\n",
    "    param_dist = {\"n_estimators\": [100, 250, 500, 1000]}\n",
    "    base_model = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "    return param_dist, base_model\n",
    "\n",
    "\n",
    "def model_svr():\n",
    "    param_dist = {'C': [0.25, 0.5, 1, 1.25]}\n",
    "    base_model = LinearSVR(loss = 'squared_epsilon_insensitive', dual=False, max_iter=10000)\n",
    "    return param_dist, base_model\n",
    "\n",
    "def random_search_cv(model, param, scoring, n_iter, x, y, verbosity=0):\n",
    "    random_fit = RandomizedSearchCV(estimator=model,\n",
    "                                    param_distributions=param,\n",
    "                                    scoring=scoring,\n",
    "                                    n_iter=n_iter,\n",
    "                                    cv=5,\n",
    "                                    random_state=0,\n",
    "                                    verbose=verbosity, refit=scoring[0])\n",
    "    random_fit.fit(x, y)\n",
    "    return random_fit\n",
    "\n",
    "def GBT_model(x, y):\n",
    "    GBT_fit = GradientBoostingRegressor(min_samples_leaf = 4,\n",
    "                                     min_samples_split = 10,\n",
    "                                     max_features = 7,\n",
    "                                     max_depth = 49,\n",
    "                                     n_estimators = 500,\n",
    "                                     subsample = 0.2,\n",
    "                                     random_state = 0)\n",
    "    GBT_fit.fit(x,y)\n",
    "    return GBT_fit\n",
    "\n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    mape = metrics.mean_absolute_percentage_error(true, predicted)\n",
    "    exp_var = metrics.explained_variance_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square, mape, exp_var\n",
    "\n",
    "\n",
    "def fit(x_train, y_train, model, model_param, general_params):\n",
    "    \"\"\"\n",
    "    Fit model\n",
    "\n",
    "    Args:\n",
    "        - model(callable): Sklearn / imblearn model\n",
    "        - model_param(dict): sklearn's RandomizedSearchCV param_distribution\n",
    "        - general_params(dict):x general parameters for the function\n",
    "            - target(str) : y column to be used   \n",
    "            - scoring(str) : sklearn cross-val scoring scheme\n",
    "            - n_iter_search : RandomizedSearchCV number of iteration\n",
    "    \"\"\"\n",
    "    #print( general_params['scoring'])\n",
    "\n",
    "    model_fitted = random_search_cv(model, model_param,\n",
    "                                    general_params['scoring'],\n",
    "                                    general_params['n_iter_search'],\n",
    "                                    x_train, y_train,\n",
    "                                    general_params['verbosity'])\n",
    "\n",
    "    \n",
    "    print(\n",
    "        f'Model: {model_fitted.best_estimator_}, {general_params[\"scoring\"][0]}: {model_fitted.best_score_}')\n",
    "\n",
    "    return model_fitted, model_fitted.best_estimator_\n",
    "\n",
    "def GBTfit(x_train, y_train):\n",
    "    \"\"\"\n",
    "    Fit model\n",
    "\n",
    "    Args:\n",
    "        - model(callable): Sklearn / imblearn model\n",
    "        - model_param(dict): sklearn's RandomizedSearchCV param_distribution\n",
    "        - general_params(dict):x general parameters for the function\n",
    "            - target(str) : y column to be used   \n",
    "            - scoring(str) : sklearn cross-val scoring scheme\n",
    "            - n_iter_search : RandomizedSearchCV number of iteration\n",
    "    \"\"\"\n",
    "    #print( general_params['scoring'])\n",
    "\n",
    "    model_fitted = GBT_model(x_train, y_train)\n",
    "\n",
    "    return model_fitted\n",
    "\n",
    "\n",
    "def validation_score(x_valid, y_valid, model_fitted):\n",
    "    \n",
    "    # Report default\n",
    "    y_predicted = model_fitted.predict(x_valid)\n",
    "    mae, mse, rmse, r2_square, mape, exp_var = evaluate(y_valid, y_predicted)\n",
    "    score = {'mae':mae, 'mse':mse, 'rmse':rmse, 'r2': r2_square, 'mape': mape, 'exp_var': exp_var}\n",
    "    print(rmse)\n",
    "    return score\n",
    "\n",
    "def select_model(train_log_dict):\n",
    "    temp = []\n",
    "    for score in train_log_dict['model_score']:\n",
    "        temp.append(score['rmse'])\n",
    "    #print(temp)\n",
    "    best_model = train_log_dict['model_name'][temp.index(min(temp))]\n",
    "    \n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(params):\n",
    "\n",
    "    #lasso = model_lasso\n",
    "    #rf = model_rf\n",
    "    #lsvr = model_svr\n",
    "\n",
    "    train_log_dict = {'model_name': [],\n",
    "                        'fit_time': [],\n",
    "                        'model_score' : []}\n",
    "   \n",
    "\n",
    "    x_train, y_train, x_valid, y_valid, x_test  = read_data(params)\n",
    "    t0 = time.time()\n",
    "    train_log_dict['model_name'].append('Gradient_boost')\n",
    "    fitted_model = GBTfit(x_train, y_train)\n",
    "    elapsed_time = time.time() - t0\n",
    "    print(f'elapsed time: {elapsed_time} s \\n')\n",
    "    train_log_dict['fit_time'].append(elapsed_time)\n",
    "    score = validation_score( x_valid, y_valid, fitted_model)\n",
    "    train_log_dict['model_score'].append(score)\n",
    "\n",
    "    best_model = select_model(\n",
    "        train_log_dict)\n",
    "    print(\n",
    "        f\"Model: {best_model}\")\n",
    "    joblib.dump(best_model, 'output/isrelated_model.pkl')\n",
    "    y_predicted = fitted_model.predict(x_test)\n",
    "    return y_predicted\n",
    "    #joblib.dump(best_parameter, 'output/isrelated_parameter.pkl')\n",
    "    #joblib.dump(train_log_dict, 'output/isrelated_train_log.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"src/params/param.yaml\", \"r\")\n",
    "params = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test = read_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 105.7530369758606 s \n",
      "\n",
      "358.16333896186563\n",
      "Model: Gradient_boost\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 27.76495531,  54.48923397,   6.98672068, ..., 311.22121338,\n",
       "        22.22011698,  35.71234371])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
